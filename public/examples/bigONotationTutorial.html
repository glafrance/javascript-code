Big O notation is used in computer science to describe the performance or complexity of an algorithm.<br /><br />

Big O notation deals specifically with the worst-case scenario, in terms of execution time or memory/disk used by an algorithm.<br /><br />

<h2>O(1)</h2><br />

O(1) describes an algorithm that executes in the same time or uses the same memory/disk space, regardless of the size of the input data set:<br /><br />

<pre>
function checkFirstItemNull(arr) {
  return (arr[0] === null);
}
</pre><br />

The above function always compares the first value in the array with the value null, and returns the result of that comparison. It doesn't matter if the array contains a single item, or contains one million items, the execution time and memory/disk requirements are the same.<br /><br />

The blue line in the following graph shows how the execution time for an O(1) algorithm is always the same.<br /><br />

<img class="bigo-img" src="/resources/images/bigo/0_1.png" /><br />

You don't really understand Big O unless you can look at an algorithm and express it in Big O notation. How can you recognize an O(1) algorithm? No matter how big the input is, there is only one output, like the function above.<br /><br />

<h2>O(N)</h2><br />

O(N) describes an algorithm whose performance is linear in relationship to the size of the input data.<br /><br />

<pre>
function contains(arr, val) {
  var retVal = false, idx, len = arr.length;
  
  for (idx = 0;idx < len;idx++) {
    if (arr[idx] === val) {
      return true;
    }
  }
  
  return retVal;
}
</pre><br />

For the above function, the performance decreases linearly as the size of the input array increases.<br /><br />

Note that Big O notation represents the worst-case scenario for algorithms. So the above function could return early if the val is found, for example, in the middle of arr, but Big O assumes the worst, that the entire array is searched.<br /><br />

<img class="bigo-img" src="/resources/images/bigo/0_N.png" /><br />

As seen in the above image, when the data set gets to 100, execution time is also at 100. This linear progression represents O(N).<br /><br />

How can you recognize an O(N) algorithm? Algorithms whose performance change is linear iterate n times. Counting quarters one-by-one is a linear operation, the more quarters, the longer it takes to count them (n operations).<br /><br />

<h2>O(N&sup2;)</h2><br />

O(N&sup2;) describes an algorithm whose performance is directly proportional to the square of the input data set size. You commonly see this in algorithms with nested interations over the data set. Iterations nested three, four, or more levels deep will result in O(N&sup3;), O(N^4), etc.<br /><br />

You also see O(N&sup2;) algorithms when every combination of input collections must be checked. O(N&sup2;) is also known as "quadratic time", and O(N&sup3;) as cubic time.<br /><br />

<pre>
function checkDuplicates(arr) {
  var idx1, idx2, len = arr.length;

  for (idx1 = 0;idx1 < len;idx1++) {
    for (idx2 = 0;idx2 < len;idx2++) {
      // don't compare an item with itself
      if(idx1 === idx2) {
        continue;
      }

      if (arr[idx1] === arr[idx2]) {
        return true;
      } 
    }
  }

  return false;
}
</pre><br />

In the above function, because the inner loop iterates the entire array for each pass of the outer loop, this algorithm is O(N&sup2;). For an array of 10 elements, that is 100 iterations (10 x 10).<br /><br />

<img class="bigo-img" src="/resources/images/bigo/0_N2.png" /><br />

Notice the dramatic increase is number of operations for increases in the data set, compared to O(1) and O(N), for algorithms of O(N&sup2;) time complexity.<br /><br />

How can you recognize an O(N&sup2;) algorithm? Look for a loop that executes N times, inside a loop that executes N times, or look for sitations where all combinations of multiple collections of items are compared.<br /><br />

<h2>O(2^N)</h2><br />

O(2^N) describes an algorithm whose execution time doubles with each additional element in the data set. O(2^N) algorithms execute in exponential time, and are impractical when the input size becomes fairly large.<br /><br />

An example of an O(2^N) algorithm is recursive computation of Fibonacci numbers.<br /><br />

<pre>
function fib(n) {
  if (n <= 1) {
    return n;
  } else {
    return fib(n - 2) + fib(n - 1);
  }
}
</pre><br />

<img class="bigo-img" src="/resources/images/bigo/0_2N.png" /><br />

<h2>O(logN)</h2><br />

O(logN) logarithmic algorithms have more interesting execution patterns.<br /><br />

A good example of a O(logN) algorithm a binary search. In a binary search of a list of sorted numbers, the number to be found is compared with the number at the middle of the sorted list. If there is a match then the search is over, otherwise another binary search is performed on either the left or right half of the sorted list, depending on whether the search target number is greater than or less than the middle list number. This continues with the searched list being halved with each search step until a match is found, or until it is determined that the list does not contain the search number.<br /><br />

The execution time of the binary search flattens out as it progresses because the input data set grows smaller with each iteration. Here is an example of a function performing a binary search:<br /><br />

<pre>
function binarySearch(arr, key) {
  var low = 0, high = arr.length - 1;
  var mid;

  while (high >= low) {
    mid = parseInt((low + high) / 2);

    if (key < arr[mid]) {
      high = mid - 1;
    } else if (key === arr[mid]) {
      return mid;          
    } else {
      low = mid + 1;  
    }
  }
  return -1;
}

var testArray = [3, 9, 16, 22, 28, 31, 45, 48, 64, 71, 93];
      
console.log("0: " + binarySearch(testArray, 3));
console.log("10: " + binarySearch(testArray, 93));
console.log("4: " + binarySearch(testArray, 28));
console.log("-1: " + binarySearch(testArray, 1));
console.log("-1: " + binarySearch(testArray, 100));
console.log("-1: " + binarySearch(testArray, 29));
</pre><br />

<img class="bigo-img" src="/resources/images/bigo/0_logN.png" /><br />

<h2>O(N!)</h2><br />

O(N!) algorithms are famous for having terrible execution efficiency.<br /><br />

A good example of a O(N!) algorithm is solving the traveling salesman problem with a brute-force search. In general, any algorithm that calculates all permutation of a given array is O(N!). Here is a very quick example (WARNING, USING AN INPUT VALUE GREATER THAN 10 OR 11 COULD FREEZE UP YOUR BROWSER !!!):<br /><br />

<pre>
function nFactorial (n) {
  for (var i = 0;i < n;i++) {
    nFactorial(n - 1);
  }
}

var start;

start = Date.now();
nFactorial(10);
console.log((Date.now() - start)/1000);

start = Date.now();
nFactorial(11);
console.log((Date.now() - start)/1000);

WARNING, USING AN INPUT VALUE GREATER THAN 10 OR 11 COULD FREEZE UP YOUR BROWSER !!!
start = Date.now();
nFactorial(12);
console.log((Date.now() - start)/1000);
</pre><br />

On my crappy laptop, here is the time required for values of 10, 11, and 12:<br /><br />

input of 10: 0.193 seconds<br />
input of 11: 2.139 seconds<br />
input of 12: 25.896 seconds<br /><br />

As you can see, if you are writing code and you end up with an O(N!) algorithm, you need to make some improvements!<br /><br />

In the traveling salesman problem, a classic O(N!) problem, you are given a list of cities and the distances between each pair of cities, and you need to figure out the shortest possible route that visits each city exactly once and then returns to the origin city.<br /><br />

<img class="bigo-img" src="/resources/images/bigo/0_Nfactorial.png" /><br />
<br />

That's it for now. Hopefully this enhances your understanding of Big O notation, and inspires you to do more research on the topic. A greater understanding of Big O notation, analysis on algorithms in terms of Big O, and being able to recognize the execution efficiency of an algorithm, can help in job interviews, and can help you write better code!<br />
<br /> 